# üìä Churn Predictor - Gu√≠a de Uso

## Descripci√≥n General

`ChurnPredictor` es una clase especializada en Machine Learning para **identificar clientes en riesgo de abandono** usando **XGBoost**, uno de los algoritmos de clasificaci√≥n m√°s poderosos en la industria.

## üéØ Caracter√≠sticas

- ‚úÖ Detecci√≥n autom√°tica de clientes en riesgo
- ‚úÖ Definici√≥n de churn basada en recency (>90 d√≠as sin compra)
- ‚úÖ Features robustas (frequency, monetary, avg_ticket)
- ‚úÖ Prevenci√≥n de data leakage
- ‚úÖ M√©tricas detalladas de clasificaci√≥n
- ‚úÖ Importancia de features explicable
- ‚úÖ Modelo guardado en pickle para producci√≥n

## üì¶ Requisitos

```
xgboost>=2.0.0
scikit-learn>=1.3.0
pandas>=2.0.3
numpy>=1.24.3
```

Instalar:
```bash
pip install xgboost scikit-learn
```

## üöÄ Uso R√°pido

### 1. Entrenar el Modelo

```python
from src.models.churn_predictor import ChurnPredictor

# Crear y entrenar
predictor = ChurnPredictor()
predictor.train(test_size=0.2)
```

### 2. Cargar Modelo Preentrenado

```python
predictor = ChurnPredictor()
predictor.load_model()
```

### 3. Hacer Predicciones

```python
# Probabilidad de churn
probabilities = predictor.predict_churn_probability(X)

# Clasificaci√≥n binaria (0/1)
predictions = predictor.predict(X)

# Importancia de features
importance = predictor.get_feature_importance()
```

## üìà Definici√≥n de Churn

```
is_churn = 1  si  recency > 90 d√≠as  (sin compras por >3 meses)
is_churn = 0  si  recency ‚â§ 90 d√≠as  (cliente activo)
```

## üîë Features Utilizadas

| Feature | Descripci√≥n | C√°lculo |
|---------|-------------|---------|
| **frequency** | N√∫mero de compras del cliente | Dato directo |
| **monetary** | Valor total gastado | Dato directo |
| **avg_ticket** | Ticket promedio | monetary / frequency |

### ‚ö†Ô∏è Por qu√© NO usamos recency

- `recency` es el **tiempo desde la √∫ltima compra**
- El target `is_churn` se define directamente de `recency`
- Usar `recency` como input causar√≠a **data leakage**
- El modelo aprender√≠a a predecir el target trivialmente
- Por eso solo usamos comportamiento de gasto (frequency, monetary)

## üìä Resultados del Modelo

| M√©trica | Valor |
|---------|-------|
| **Clientes entrenados** | 49,118 |
| **Churn rate** | 77.9% |
| **Train accuracy** | 78.11% |
| **Test accuracy** | 77.79% |
| **Precision** | 0.7802 |
| **Recall** | 0.9950 |
| **F1-Score** | 0.8746 |
| **AUC-ROC** | 0.6484 |

### Explicaci√≥n de M√©tricas

- **Accuracy**: Porcentaje general de predicciones correctas
- **Precision**: De los predichos como churn, cu√°ntos realmente lo son
- **Recall**: De los clientes realmente en churn, cu√°ntos identificamos (99.5% ‚úÖ)
- **F1-Score**: Balance entre precision y recall
- **AUC-ROC**: Capacidad del modelo para discriminar entre clases

## üí° Importancia de Features

```
frequency:   59.51% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 
monetary:    21.71% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
avg_ticket:  18.78% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
```

**Interpretaci√≥n**: La frecuencia de compra es el predictor m√°s importante del abandono. Clientes que compran con baja frecuencia tienen mayor riesgo de churn.

## üîß M√©todos Principales

### `train(test_size=0.2)`
Entrena el modelo con datos de `data/processed/customer_features.csv`

```python
predictor = ChurnPredictor()
predictor.train()  # Split 80/20 autom√°tico
```

### `predict(X)`
Predice si clientes est√°n en riesgo (0 o 1)

```python
predictions = predictor.predict(new_customers_df)
# Retorna: array([1, 0, 1, ...])
```

### `predict_churn_probability(X)`
Predice probabilidad de churn (0-1)

```python
probabilities = predictor.predict_churn_probability(new_customers_df)
# Retorna: array([0.95, 0.23, 0.87, ...])
```

### `get_feature_importance()`
Obtiene importancia de features

```python
importance = predictor.get_feature_importance()
print(importance)
#     feature  importance
# 0  frequency     0.5951
# 1  monetary      0.2171
# 2  avg_ticket    0.1878
```

### `load_model()`
Carga modelo preentrenado

```python
predictor = ChurnPredictor()
predictor.load_model()
```

## üìã Matriz de Confusi√≥n Explicada

```
                 Predicho No-Churn    Predicho Churn
Real No-Churn            31              2,144
Real Churn               38              7,611
```

- **TN = 31**: Correctamente identificamos 31 clientes sin riesgo
- **FP = 2,144**: Falsos positivos (dijimos churn pero no lo eran)
- **FN = 38**: Falsos negativos (dijimos no-churn pero s√≠ lo eran) ‚Üê Problema
- **TP = 7,611**: Correctamente identificamos 7,611 en riesgo

**An√°lisis**: El modelo es muy conservador - predice casi todos como churn. Esto es mejor que los falsos negativos (clientes abandonados no detectados).

## üéì Configuraci√≥n de XGBoost

```python
XGBClassifier(
    n_estimators=100,        # 100 √°rboles
    max_depth=6,             # Profundidad m√°xima
    learning_rate=0.1,       # Tasa de aprendizaje
    subsample=0.8,           # 80% de datos por √°rbol
    colsample_bytree=0.8,    # 80% de features por √°rbol
    eval_metric='logloss'
)
```

## üíº Casos de Uso

### 1. Identificar Clientes en Riesgo
```python
predictor.load_model()
probs = predictor.predict_churn_probability(customer_data)

# Clientes con riesgo alto (>80%)
high_risk = customer_data[probs > 0.8]
```

### 2. Propensity Scoring
```python
scores = predictor.predict_churn_probability(all_customers)
customers['churn_risk_score'] = scores

# Segmentar por riesgo
low_risk = customers[scores < 0.3]
medium_risk = customers[(scores >= 0.3) & (scores < 0.7)]
high_risk = customers[scores >= 0.7]
```

### 3. Campa√±a de Retenci√≥n
```python
# Clientes recientes a retener
to_retain = high_risk[high_risk['frequency'] > 3]
print(f"Enviar ofertas a {len(to_retain)} clientes")
```

## ‚ö†Ô∏è Limitaciones

1. **Recency > 90 d√≠as**: Es una definici√≥n simple de churn
2. **No considera contexto**: Industria, estacionalidad, etc.
3. **Data labeling**: Usa recency como proxy de churn
4. **Clase desbalanceada**: 77.9% churn vs 22.1% activos
5. **Require actualizaci√≥n**: El modelo se vuelve obsoleto con el tiempo

## üîÑ Mejoras Posibles

- Incorporar features temporales (seasonality)
- Crear m√∫ltiples modelos por segmento
- Usar threshold din√°mico seg√∫n costo de FP/FN
- Implementar reentrenamiento autom√°tico
- Agregar features de comportamiento web/app

## üìû Troubleshooting

### Error: `ModuleNotFoundError: xgboost`
```bash
pip install xgboost
```

### Error: `FileNotFoundError: customer_features.csv`
```bash
# Aseg√∫rate que el archivo existe en:
data/processed/customer_features.csv
```

### Accuracy bajo
- Revisar data quality
- Ajustar threshold de recency (>90)
- Reentrenar con datos m√°s recientes

## üìö Archivos Relacionados

- [CHURN_PREDICTOR_EXAMPLES.md](CHURN_PREDICTOR_EXAMPLES.md) - Ejemplos de c√≥digo
- [README_SALES_PREDICTOR.md](README_SALES_PREDICTOR.md) - Modelo de ventas
- [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md) - Resumen t√©cnico

---

**√öltima Actualizaci√≥n:** 2026-01-09  
**Versi√≥n:** 1.0.0  
**Accuracy:** 77.79%
